{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ssm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "\n",
    "from notebooks.imports import *\n",
    "from config import dir_config, main_config\n",
    "from src.utils.glm_hmm_utils import *\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import dir_config, main_config\n",
    "\n",
    "raw_dir = Path(dir_config.data.raw)\n",
    "processed_dir = Path(dir_config.data.processed)\n",
    "\n",
    "metadata = pd.read_csv(Path(processed_dir, \"processed_metadata_accu_60.csv\"))\n",
    "data = pd.read_csv(Path(processed_dir, \"processed_data_accu_60_all.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_sites = [\"Stanford\"]\n",
    "\n",
    "metadata = metadata[metadata['experiment_site'].isin(experiment_sites)].reset_index(drop=True)\n",
    "data = data[data['subject_id'].isin(metadata['subject_id'])].reset_index(drop=True)\n",
    "\n",
    "# add session_id to data with matching subject_id and medication\n",
    "metadata['session_id'] = metadata[['subject_id', 'treatment']].apply(lambda x: '_'.join(x.astype(str).str.upper()), axis=1)\n",
    "data['session_id'] = data[['subject_id', 'medication']].apply(lambda x: '_'.join(x.astype(str).str.upper()), axis=1)\n",
    "data.choice = data.choice.fillna(-1).astype(int)\n",
    "data.target = data.target.fillna(-1).astype(int)\n",
    "data.outcome = data.outcome.fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_previous_trial_data(trial_data, invalid_idx):\n",
    "    npr.seed(1)\n",
    "    prev_choice = np.hstack([trial_data.choice[0], trial_data.choice[:-1]])  # 0:awayPrior, 1:toPrior of previous valid trial\n",
    "    prev_target = np.hstack([trial_data.target[0], trial_data.target[:-1]]) * 2 - 1  # 0:awayPrior, 1:toPrior of previous valid trial\n",
    "    prev_color = np.hstack([trial_data.color[0], trial_data.color[:-1]])  # 0:equalPrior, 1:UnequalPrior of previous valid trial\n",
    "\n",
    "    # indices where the previous trial is invalid/valid\n",
    "    prev_invalid_idx = np.array(invalid_idx) + 1\n",
    "    if 0 in invalid_idx:\n",
    "        prev_invalid_idx = np.append(0, prev_invalid_idx)\n",
    "    prev_valid_idx = np.setdiff1d(np.arange(len(trial_data)), prev_invalid_idx)\n",
    "\n",
    "    for i in prev_invalid_idx[prev_invalid_idx < len(trial_data)]:\n",
    "        if i < prev_valid_idx[0]: #randomly sample if no previous valid trials\n",
    "            prev_choice[i] = np.random.binomial(1,0.5)\n",
    "            prev_target[i] = np.random.binomial(1,0.5) * 2 - 1\n",
    "            prev_color[i]  = np.random.binomial(1,0.5)\n",
    "        else:\n",
    "            last_valid =  np.where(prev_valid_idx<i)[0][-1]\n",
    "            prev_choice[i] = prev_choice[prev_valid_idx[last_valid]]\n",
    "            prev_target[i] = prev_target[prev_valid_idx[last_valid]]\n",
    "            prev_color[i] = prev_color[prev_valid_idx[last_valid]]\n",
    "\n",
    "    prev_choice = (prev_choice * 2) - 1 # -1:awayPrior, 1:toPrior of previous valid trial\n",
    "    return prev_choice.astype(int), prev_target.astype(int), prev_color.astype(int)\n",
    "\n",
    "def prepare_input_data(data, input_dim, invalid_idx):\n",
    "    X = np.ones((1, data.shape[0], input_dim))\n",
    "\n",
    "    X[0,:,0] = data.signed_coherence / 100\n",
    "    X[0,:,1] = data.color\n",
    "\n",
    "    prev_choice, prev_target, prev_color = extract_previous_trial_data(data, invalid_idx)\n",
    "    if input_dim == 4:\n",
    "        X[0,:,3] = prev_choice\n",
    "    elif input_dim == 5:\n",
    "        X[0,:,3] = prev_choice\n",
    "        X[0,:,4] = prev_target\n",
    "    elif input_dim == 6:\n",
    "        X[0,:,3] = prev_choice\n",
    "        X[0,:,4] = prev_target\n",
    "        X[0,:,5] = prev_color\n",
    "    return list(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------- info ----------------\")\n",
    "print(data.info())\n",
    "print(\"------------- Head ----------------\")\n",
    "print(data.head())\n",
    "print(\"\\n\\n------------- describe ----------------\\n\\n\")\n",
    "print(data.describe())\n",
    "print(\"------------- nan counts ----------------\")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\n\\n------------- dtypes ----------------\\n\\n\")\n",
    "print(data.dtypes)\n",
    "print(\"\\n\\n------------- shape ----------------\\n\\n\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_med_sessions = metadata[metadata['treatment'] == 'OFF'].session_id.unique()\n",
    "on_med_sessions = metadata[metadata['treatment'] == 'ON'].session_id.unique()\n",
    "off_med_sessions, on_med_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create design matrix (input, output, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 2       # number of discrete states\n",
    "obs_dim = 1           # number of observed dimensions: choice(toPrior/awayPrior)\n",
    "num_categories = 2    # number of categories for output\n",
    "input_dim = 5        # input dimensions: current signed coherence, current stimulus color, 1(bias), previous choice(toPrior/awayPrior), previous target side(toPrior/awayPrior), previous color(toPrior/awayPrior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Off medication sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_session_wise = []\n",
    "choices_session_wise = []\n",
    "invalid_idx_session_wise = []\n",
    "masks_session_wise = []\n",
    "reaction_time_session_wise = []\n",
    "\n",
    "# off medication sessions\n",
    "for session in off_med_sessions:\n",
    "    session_data = data[data['session_id'] == session].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    invalid_idx = np.where(session_data.outcome < 0)[0]\n",
    "    valid_idx = np.where(session_data.outcome >= 0)[0]\n",
    "\n",
    "    inputs = prepare_input_data(session_data, input_dim, invalid_idx)\n",
    "    choices = session_data.choice.values.reshape(-1,1).astype('int')\n",
    "\n",
    "    # for training, replace -1 with random sample from 0,1\n",
    "    choices[choices == -1] = npr.choice([0,1],invalid_idx.shape[0])\n",
    "    mask = np.ones_like(choices, dtype=bool)\n",
    "    mask[invalid_idx] = 0\n",
    "    reaction_time = np.array(session_data.reaction_time)\n",
    "\n",
    "    masks_session_wise.append(mask)\n",
    "    inputs_session_wise += inputs\n",
    "    choices_session_wise.append(choices)\n",
    "    reaction_time_session_wise.append(reaction_time)\n",
    "\n",
    "off_med_inputs_aggregate, off_med_choices_aggregate, off_med_masks_aggregate = [], [], []\n",
    "off_med_inputs_aggregate.append(np.vstack(inputs_session_wise))\n",
    "off_med_choices_aggregate.append(np.vstack(choices_session_wise))\n",
    "off_med_masks_aggregate.append(np.vstack(masks_session_wise))\n",
    "\n",
    "unnormalized_off_med_inputs = copy.deepcopy(inputs_session_wise)\n",
    "\n",
    "# scaling signed coherence\n",
    "off_med_inputs_aggregate[0][off_med_masks_aggregate[0][:,0],0] = preprocessing.scale(off_med_inputs_aggregate[0][off_med_masks_aggregate[0][:,0],0], axis=0)\n",
    "for idx in range(len(off_med_sessions)):\n",
    "    inputs_session_wise[idx][masks_session_wise[idx][:,0],0] = preprocessing.scale(inputs_session_wise[idx][masks_session_wise[idx][:,0],0], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_glm_hmm_off_med, fit_lls_glm_hmm_off_med = global_fit(off_med_choices_aggregate, off_med_inputs_aggregate, masks=off_med_masks_aggregate, n_iters= 1000, n_initializations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best model of 20 initializations for each state\n",
    "init_params = {\n",
    "    'glm_weights': {},\n",
    "    'transition_matrices': {}\n",
    "}\n",
    "for n_states in np.arange(2,6):\n",
    "    best_idx = fit_lls_glm_hmm_off_med[n_states].index(max(fit_lls_glm_hmm_off_med[n_states]))\n",
    "    init_params['glm_weights'][n_states] = models_glm_hmm_off_med[n_states][best_idx].observations.params\n",
    "    init_params['transition_matrices'][n_states] = models_glm_hmm_off_med[n_states][best_idx].transitions.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session-wise fitting with 5 fold cross-validation\n",
    "models_session_state_fold_off_med, train_ll_session_off_med, test_ll_session_off_med = session_wise_fit_cv(choices_session_wise, inputs_session_wise, masks=masks_session_wise,\n",
    "                                                                                    n_sessions=len(off_med_sessions), init_params=init_params, n_iters= 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_medication_results = {\n",
    "    'global':{\n",
    "\t\t'inputs': off_med_inputs_aggregate,\n",
    "\t\t'choices': off_med_choices_aggregate,\n",
    "\t\t'masks': off_med_masks_aggregate,\n",
    "\t\t'models': models_glm_hmm_off_med,\n",
    "\t\t'fit_lls': fit_lls_glm_hmm_off_med,\n",
    "\t\t'best_params': init_params\n",
    "\t},\n",
    "\t'session':{\n",
    "\t\t'session_ids': off_med_sessions,\n",
    "        'unnormalized_inputs': unnormalized_off_med_inputs,\n",
    "\t\t'inputs': inputs_session_wise,\n",
    "\t\t'choices': choices_session_wise,\n",
    "\t\t'masks': masks_session_wise,\n",
    "\t\t'reaction_time': reaction_time_session_wise,\n",
    "\t\t'models': models_session_state_fold_off_med,\n",
    "\t\t'train_lls': train_ll_session_off_med,\n",
    "\t\t'test_lls': test_ll_session_off_med\n",
    "\t}\n",
    "}\n",
    "\n",
    "\n",
    "# with open(Path(processed_dir, f'glm_hmm_off_meds_result.pkl'), 'wb') as f:\n",
    "#     pickle.dump(off_medication_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On medication sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_session_wise = []\n",
    "choices_session_wise = []\n",
    "invalid_idx_session_wise = []\n",
    "masks_session_wise = []\n",
    "reaction_time_session_wise = []\n",
    "\n",
    "# on medication sessions\n",
    "for session in on_med_sessions:\n",
    "    session_data = data[data['session_id'] == session].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    invalid_idx = np.where(session_data.outcome < 0)[0]\n",
    "    valid_idx = np.where(session_data.outcome >= 0)[0]\n",
    "\n",
    "    inputs = prepare_input_data(session_data, input_dim, invalid_idx)\n",
    "    choices = session_data.choice.values.reshape(-1,1).astype('int')\n",
    "\n",
    "    # for training, replace -1 with random sample from 0,1\n",
    "    choices[choices == -1] = npr.choice([0,1],invalid_idx.shape[0])\n",
    "    mask = np.ones_like(choices, dtype=bool)\n",
    "    mask[invalid_idx] = 0\n",
    "    reaction_time = np.array(session_data.reaction_time)\n",
    "\n",
    "    masks_session_wise.append(mask)\n",
    "    inputs_session_wise += inputs\n",
    "    choices_session_wise.append(choices)\n",
    "    reaction_time_session_wise.append(reaction_time)\n",
    "\n",
    "on_med_inputs_aggregate, on_med_choices_aggregate, on_med_masks_aggregate = [], [], []\n",
    "on_med_inputs_aggregate.append(np.vstack(inputs_session_wise))\n",
    "on_med_choices_aggregate.append(np.vstack(choices_session_wise))\n",
    "on_med_masks_aggregate.append(np.vstack(masks_session_wise))\n",
    "\n",
    "unnormalized_on_med_inputs = copy.deepcopy(inputs_session_wise)\n",
    "\n",
    "# scaling signed coherence\n",
    "on_med_inputs_aggregate[0][on_med_masks_aggregate[0][:,0],0] = preprocessing.scale(on_med_inputs_aggregate[0][on_med_masks_aggregate[0][:,0],0], axis=0)\n",
    "for idx in range(len(on_med_sessions)):\n",
    "    inputs_session_wise[idx][masks_session_wise[idx][:,0],0] = preprocessing.scale(inputs_session_wise[idx][masks_session_wise[idx][:,0],0], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_glm_hmm_on_med, fit_lls_glm_hmm_on_med = global_fit(on_med_choices_aggregate, on_med_inputs_aggregate, masks=on_med_masks_aggregate, n_iters= 1000, n_initializations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best model of 20 initializations for each state\n",
    "init_params = {\n",
    "    'glm_weights': {},\n",
    "    'transition_matrices': {}\n",
    "}\n",
    "for n_states in np.arange(2,6):\n",
    "    best_idx = fit_lls_glm_hmm_on_med[n_states].index(max(fit_lls_glm_hmm_on_med[n_states]))\n",
    "    init_params['glm_weights'][n_states] = models_glm_hmm_on_med[n_states][best_idx].observations.params\n",
    "    init_params['transition_matrices'][n_states] = models_glm_hmm_on_med[n_states][best_idx].transitions.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session-wise fitting with 5 fold cross-validation\n",
    "models_session_state_fold_on_med, train_ll_session_on_med, test_ll_session_on_med = session_wise_fit_cv(choices_session_wise, inputs_session_wise, masks=masks_session_wise,\n",
    "                                                                                    n_sessions=len(on_med_sessions), init_params=init_params, n_iters= 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_medication_results = {\n",
    "    'global':{\n",
    "\t\t'inputs': on_med_inputs_aggregate,\n",
    "\t\t'choices': on_med_choices_aggregate,\n",
    "\t\t'masks': on_med_masks_aggregate,\n",
    "\t\t'models': models_glm_hmm_on_med,\n",
    "\t\t'fit_lls': fit_lls_glm_hmm_on_med,\n",
    "\t\t'best_params': init_params\n",
    "\t},\n",
    "\t'session':{\n",
    "\t\t'session_ids': on_med_sessions,\n",
    "        'unnormalized_inputs': unnormalized_on_med_inputs,\n",
    "\t\t'inputs': inputs_session_wise,\n",
    "\t\t'choices': choices_session_wise,\n",
    "\t\t'masks': masks_session_wise,\n",
    "\t\t'reaction_time': reaction_time_session_wise,\n",
    "\t\t'models': models_session_state_fold_on_med,\n",
    "\t\t'train_lls': train_ll_session_on_med,\n",
    "\t\t'test_lls': test_ll_session_on_med\n",
    "\t}\n",
    "}\n",
    "\n",
    "# with open(Path(processed_dir, f'glm_hmm_on_meds_result.pkl'), 'wb') as f:\n",
    "#     pickle.dump(on_medication_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_medication_results[\"session\"].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_hmm_results = {\n",
    "    \"off_med_global\": off_medication_results['global'],\n",
    "    \"on_med_global\": on_medication_results['global'],\n",
    "    \"session_wise\": {\n",
    "        \"session_ids\": off_medication_results['session']['session_ids'].tolist() + on_medication_results['session']['session_ids'].tolist(),\n",
    "        \"unnormalized_inputs\": off_medication_results['session']['unnormalized_inputs'] + on_medication_results['session']['unnormalized_inputs'],\n",
    "\t\t\"inputs\": off_medication_results['session']['inputs'] + on_medication_results['session']['inputs'],\n",
    "\t\t\"choices\": off_medication_results['session']['choices'] + on_medication_results['session']['choices'],\n",
    "\t\t\"masks\": off_medication_results['session']['masks'] + on_medication_results['session']['masks'],\n",
    "\t\t\"reaction_time\": off_medication_results['session']['reaction_time'] + on_medication_results['session']['reaction_time'],\n",
    "        \"train_ll\": np.concatenate([off_medication_results['session']['train_lls'], on_medication_results['session']['train_lls']], axis=0),\n",
    "        \"test_ll\": np.concatenate([off_medication_results['session']['test_lls'], on_medication_results['session']['test_lls']], axis=0)\n",
    "    }\n",
    "}\n",
    "\n",
    "glm_hmm_results['session_wise']['models'] = models_session_state_fold_off_med\n",
    "# Shift the keys of on-medication models and merge\n",
    "off_session_len = len(models_session_state_fold_off_med)  # Fix variable name\n",
    "glm_hmm_results['session_wise']['models'].update({\n",
    "    key + off_session_len: value for key, value in models_session_state_fold_on_med.items()\n",
    "})\n",
    "\n",
    "\n",
    "with open(Path(processed_dir, f'glm_hmm_separate_initialization_result.pkl'), 'wb') as f:\n",
    "    pickle.dump(glm_hmm_results, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
